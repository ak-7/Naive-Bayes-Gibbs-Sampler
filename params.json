{"note":"Don't delete this file! It's used internally to help with page regeneration.","google":"","body":"Naive Bayes Gibbs Sampler\r\n=========================\r\n\r\nThis project implements the Gibbs sampler for Naive Bayes document classification described in [Resnik and Hardisty 2010, \"Gibbs Sampling for the Uninitiated\"](http://drum.lib.umd.edu/handle/1903/10058).\r\nIt closely follows the notation and design put forth in that paper.\r\n\r\nThere are only two significant differences between the algorithm presented in the paper and the code here.\r\nUnlike the paper, this code allows the documents to be grouped into more than two classes, so document priors\r\nare generated using a Dirichlet distribution rather than a Beta distribution.\r\nAlso the equations in the paper are written in terms of probabilities, whereas to avoid underflow errors this code works with log probabilities. \r\n\r\nThis code depends on [Numeric Python](http://numpy.scipy.org/).\r\n","name":"Naive-bayes-gibbs-sampler","tagline":"Gibbs sampler for for a Naive Bayes document classifier"}